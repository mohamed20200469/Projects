{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-15T16:04:17.098730Z","iopub.status.busy":"2024-05-15T16:04:17.098337Z","iopub.status.idle":"2024-05-15T16:04:34.739925Z","shell.execute_reply":"2024-05-15T16:04:34.738773Z","shell.execute_reply.started":"2024-05-15T16:04:17.098703Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-15 16:04:20.755449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-15 16:04:20.755571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-15 16:04:20.920373: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import nltk\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.743183Z","iopub.status.busy":"2024-05-15T16:04:34.742062Z","iopub.status.idle":"2024-05-15T16:04:34.751019Z","shell.execute_reply":"2024-05-15T16:04:34.750039Z","shell.execute_reply.started":"2024-05-15T16:04:34.743124Z"},"trusted":true},"outputs":[],"source":["def pre_process(df, column_name):\n","    \n","    # Get English stopwords\n","    stop_words = set(stopwords.words('english'))\n","    \n","    # Function to remove stopwords from a text\n","    def remove_stopwords_from_text(text):\n","        if isinstance(text, str):\n","            word_tokens = word_tokenize(text)\n","            filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n","            return ' '.join(filtered_text)\n","        else:\n","            return text\n","    \n","    # Apply the function to the specified column\n","    df[column_name] = df[column_name].apply(remove_stopwords_from_text)\n","    \n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.753289Z","iopub.status.busy":"2024-05-15T16:04:34.752528Z","iopub.status.idle":"2024-05-15T16:04:34.851792Z","shell.execute_reply":"2024-05-15T16:04:34.850443Z","shell.execute_reply.started":"2024-05-15T16:04:34.753251Z"},"trusted":true},"outputs":[],"source":["def split_data(df, test_size=0.2, random_state=None):\n","    X_train, X_test, Y_train, Y_test = train_test_split(df[\"cleaned_review\"], df[\"sentiments\"], test_size=test_size, random_state=random_state)\n","    \n","    # Convert X_train, X_test, Y_train, Y_test to TensorFlow tensors\n","    X_train = tf.convert_to_tensor([tf.convert_to_tensor(x) for x in X_train])\n","    X_test = tf.convert_to_tensor([tf.convert_to_tensor(x) for x in X_test])\n","    Y_train = tf.convert_to_tensor([tf.convert_to_tensor(y) for y in Y_train])\n","    Y_test = tf.convert_to_tensor([tf.convert_to_tensor(y) for y in Y_test])\n","    \n","    \n","    return X_train, X_test, Y_train, Y_test"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.854639Z","iopub.status.busy":"2024-05-15T16:04:34.854217Z","iopub.status.idle":"2024-05-15T16:04:34.862627Z","shell.execute_reply":"2024-05-15T16:04:34.861209Z","shell.execute_reply.started":"2024-05-15T16:04:34.854601Z"},"trusted":true},"outputs":[],"source":["def encode(column):\n","    \n","    class_to_label = {'positive': 0, 'neutral': 1, 'negative': 2}\n","    \n","    # Fit label encoder and transform the sentiment labels\n","    encoded_labels = column.map(class_to_label)\n","    \n","    return encoded_labels"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.864624Z","iopub.status.busy":"2024-05-15T16:04:34.864165Z","iopub.status.idle":"2024-05-15T16:04:34.881455Z","shell.execute_reply":"2024-05-15T16:04:34.880129Z","shell.execute_reply.started":"2024-05-15T16:04:34.864594Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","\n","word_index = defaultdict(lambda: len(word_index))  # Initialize an index dictionary\n","max_sequence_length = 0\n","\n","def tokenize_and_index(df, column, max_length=None):\n","    \n","    global max_sequence_length\n","    \n","    tokenized_column = []\n","\n","    for entry in df[column].astype(str):\n","        tokens = nltk.word_tokenize(entry)  # Tokenize each entry\n","        indexed_tokens = [word_index[token] for token in tokens]  # Convert tokens to indices\n","        \n","        if len(indexed_tokens) > max_sequence_length:\n","            max_sequence_length = len(indexed_tokens)\n","        \n","        tokenized_column.append(indexed_tokens)  # Append list of indices\n","    \n","    if max_length is None:\n","        max_length = max_sequence_length\n","\n","    # Pad each entry to max_length\n","    for i in range(len(tokenized_column)):\n","        tokenized_column[i] += [0] * (max_length - len(tokenized_column[i]))\n","\n","    return tokenized_column, len(word_index), max_length"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.884467Z","iopub.status.busy":"2024-05-15T16:04:34.883566Z","iopub.status.idle":"2024-05-15T16:04:34.892570Z","shell.execute_reply":"2024-05-15T16:04:34.891284Z","shell.execute_reply.started":"2024-05-15T16:04:34.884424Z"},"trusted":true},"outputs":[],"source":["def preprocess_and_encode(df, text_column, sentiment_column):\n","    # Preprocess the DataFrame\n","    df = pre_process(df, text_column)\n","    \n","    # Tokenize and index the text column\n","    df[text_column], vocab_size, max_length = tokenize_and_index(df, text_column)\n","    \n","    # Encode the sentiment column\n","    df[sentiment_column] = encode(df[sentiment_column])\n","    \n","    return df"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.895386Z","iopub.status.busy":"2024-05-15T16:04:34.894494Z","iopub.status.idle":"2024-05-15T16:04:34.905191Z","shell.execute_reply":"2024-05-15T16:04:34.904101Z","shell.execute_reply.started":"2024-05-15T16:04:34.895346Z"},"trusted":true},"outputs":[],"source":["def build_simple_rnn_model(vocab_size, len):\n","    model = Sequential([\n","        Embedding(input_dim=vocab_size, output_dim=50, input_length=len),\n","        Bidirectional(SimpleRNN(16)),\n","        Dense(16, activation='relu'),\n","        Dense(3, activation='softmax')  # 3 classes: neutral, negative, positive\n","    ])\n","    return model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.908504Z","iopub.status.busy":"2024-05-15T16:04:34.907192Z","iopub.status.idle":"2024-05-15T16:04:34.917639Z","shell.execute_reply":"2024-05-15T16:04:34.916512Z","shell.execute_reply.started":"2024-05-15T16:04:34.908463Z"},"trusted":true},"outputs":[],"source":["def build_lstm_model(vocab_size, max_seq_length):\n","    model = Sequential([\n","        Embedding(input_dim=vocab_size, output_dim=50, input_length=max_seq_length),\n","        Bidirectional(LSTM(16)),\n","        Dense(16, activation='relu'),\n","        Dense(3, activation='softmax')  # 3 classes: neutral, negative, positive\n","    ])\n","    \n","    # Compile the model\n","    optimizer = Adam(learning_rate=0.001)\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:34.919916Z","iopub.status.busy":"2024-05-15T16:04:34.918971Z","iopub.status.idle":"2024-05-15T16:04:34.933207Z","shell.execute_reply":"2024-05-15T16:04:34.932205Z","shell.execute_reply.started":"2024-05-15T16:04:34.919881Z"},"trusted":true},"outputs":[],"source":["def train_and_evaluate_model(model, X_train, Y_train, X_test, Y_test):\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.fit(X_train, Y_train, epochs=5, batch_size=32, verbose=0)\n","    _, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n","    return accuracy"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:09:34.061776Z","iopub.status.busy":"2024-05-15T16:09:34.061318Z","iopub.status.idle":"2024-05-15T16:09:40.137643Z","shell.execute_reply":"2024-05-15T16:09:40.136480Z","shell.execute_reply.started":"2024-05-15T16:09:34.061743Z"},"trusted":true},"outputs":[],"source":["# Load the dataset\n","df = pd.read_csv(\"/kaggle/input/amazon-sentiment/cleaned_reviews.csv\")\n","df = preprocess_and_encode(df, \"cleaned_review\", 'sentiments')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:09:40.140228Z","iopub.status.busy":"2024-05-15T16:09:40.139821Z","iopub.status.idle":"2024-05-15T16:09:40.162472Z","shell.execute_reply":"2024-05-15T16:09:40.161619Z","shell.execute_reply.started":"2024-05-15T16:09:40.140194Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiments</th>\n","      <th>cleaned_review</th>\n","      <th>cleaned_review_length</th>\n","      <th>review_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0, 0,...</td>\n","      <td>19</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2...</td>\n","      <td>88</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[52, 53, 54, 55, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n","      <td>9</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[57, 58, 59, 7, 60, 61, 62, 15, 63, 64, 0, 0, ...</td>\n","      <td>12</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[65, 66, 67, 68, 48, 69, 70, 32, 0, 0, 0, 0, 0...</td>\n","      <td>21</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17335</th>\n","      <td>0</td>\n","      <td>[5, 3463, 5, 386, 896, 32, 982, 101, 1126, 128...</td>\n","      <td>30</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>17336</th>\n","      <td>0</td>\n","      <td>[15, 861, 318, 448, 1470, 1343, 2207, 0, 0, 0,...</td>\n","      <td>13</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>17337</th>\n","      <td>0</td>\n","      <td>[6485, 111, 243, 682, 9, 55, 32, 167, 6, 320, ...</td>\n","      <td>41</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>17338</th>\n","      <td>0</td>\n","      <td>[5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>17339</th>\n","      <td>1</td>\n","      <td>[7304, 3463, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17340 rows × 4 columns</p>\n","</div>"],"text/plain":["       sentiments                                     cleaned_review  \\\n","0               0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0, 0,...   \n","1               1  [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 2...   \n","2               1  [52, 53, 54, 55, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n","3               1  [57, 58, 59, 7, 60, 61, 62, 15, 63, 64, 0, 0, ...   \n","4               1  [65, 66, 67, 68, 48, 69, 70, 32, 0, 0, 0, 0, 0...   \n","...           ...                                                ...   \n","17335           0  [5, 3463, 5, 386, 896, 32, 982, 101, 1126, 128...   \n","17336           0  [15, 861, 318, 448, 1470, 1343, 2207, 0, 0, 0,...   \n","17337           0  [6485, 111, 243, 682, 9, 55, 32, 167, 6, 320, ...   \n","17338           0  [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","17339           1  [7304, 3463, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","       cleaned_review_length  review_score  \n","0                         19           5.0  \n","1                         88           1.0  \n","2                          9           2.0  \n","3                         12           1.0  \n","4                         21           1.0  \n","...                      ...           ...  \n","17335                     30           5.0  \n","17336                     13           4.0  \n","17337                     41           5.0  \n","17338                      2           5.0  \n","17339                      2           5.0  \n","\n","[17340 rows x 4 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-15T16:04:41.174431Z","iopub.status.busy":"2024-05-15T16:04:41.173619Z","iopub.status.idle":"2024-05-15T16:04:45.179141Z","shell.execute_reply":"2024-05-15T16:04:45.177895Z","shell.execute_reply.started":"2024-05-15T16:04:41.174395Z"},"trusted":true},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = split_data(df, test_size=0.2, random_state=41)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:04:45.181179Z","iopub.status.busy":"2024-05-15T16:04:45.180800Z","iopub.status.idle":"2024-05-15T16:04:45.195712Z","shell.execute_reply":"2024-05-15T16:04:45.194253Z","shell.execute_reply.started":"2024-05-15T16:04:45.181135Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(313,), dtype=int32, numpy=\n","array([1078,  239,  409,  429,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0], dtype=int32)>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X_train[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:09:49.409985Z","iopub.status.busy":"2024-05-15T16:09:49.409346Z","iopub.status.idle":"2024-05-15T16:09:49.416077Z","shell.execute_reply":"2024-05-15T16:09:49.415211Z","shell.execute_reply.started":"2024-05-15T16:09:49.409951Z"},"trusted":true},"outputs":[],"source":["def build_model(model_name, vocab_size, max_seq_length):\n","    if model_name == 'Simple RNN':\n","        return build_simple_rnn_model(vocab_size, max_seq_length)\n","    elif model_name == 'LSTM':\n","        return build_lstm_model(vocab_size, max_seq_length)\n","    else:\n","        raise ValueError(f\"Unknown model name: {model_name}\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T16:48:49.239620Z","iopub.status.busy":"2024-05-15T16:48:49.239190Z","iopub.status.idle":"2024-05-15T17:20:17.370543Z","shell.execute_reply":"2024-05-15T17:20:17.369440Z","shell.execute_reply.started":"2024-05-15T16:48:49.239587Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Split Ratio: 0.2\n","Max Seq Length: 50\n","Building Simple RNN...\n","Model: Simple RNN, Max Seq Length: 50, Accuracy: 0.7603806257247925\n","Building LSTM...\n","Model: LSTM, Max Seq Length: 50, Accuracy: 0.8641868233680725\n","Max Seq Length: 100\n","Building Simple RNN...\n","Model: Simple RNN, Max Seq Length: 100, Accuracy: 0.871107280254364\n","Building LSTM...\n","Model: LSTM, Max Seq Length: 100, Accuracy: 0.8731257319450378\n","Split Ratio: 0.4\n","Max Seq Length: 50\n","Building Simple RNN...\n","Model: Simple RNN, Max Seq Length: 50, Accuracy: 0.8145905137062073\n","Building LSTM...\n","Model: LSTM, Max Seq Length: 50, Accuracy: 0.8496251702308655\n","Max Seq Length: 100\n","Building Simple RNN...\n","Model: Simple RNN, Max Seq Length: 100, Accuracy: 0.839244544506073\n","Building LSTM...\n","Model: LSTM, Max Seq Length: 100, Accuracy: 0.8522202968597412\n","        Model  Split Ratio  Max Seq Length  Accuracy\n","0  Simple RNN          0.2              50  0.760381\n","1        LSTM          0.2              50  0.864187\n","2  Simple RNN          0.2             100  0.871107\n","3        LSTM          0.2             100  0.873126\n","4  Simple RNN          0.4              50  0.814591\n","5        LSTM          0.4              50  0.849625\n","6  Simple RNN          0.4             100  0.839245\n","7        LSTM          0.4             100  0.852220\n"]}],"source":["def evaluate_models_with_varied_splits(df, split_ratios, model_names, max_seq_lengths):\n","    results = []\n","    models = []\n","    for split_ratio in split_ratios:\n","        print(f\"Split Ratio: {split_ratio}\")\n","        for max_seq_length in max_seq_lengths:\n","            print(f\"Max Seq Length: {max_seq_length}\")\n","            X_train, X_test, Y_train, Y_test = split_data(df, test_size=split_ratio, random_state=41)\n","            for model_name in model_names:\n","                print(f\"Building {model_name}...\")\n","                model = build_model(model_name, len(word_index), max_seq_length)\n","                models.append(model)\n","                accuracy = train_and_evaluate_model(model, X_train, Y_train, X_test, Y_test)\n","                print(f\"Model: {model_name}, Max Seq Length: {max_seq_length}, Accuracy: {accuracy}\")\n","                results.append({'Model': model_name, 'Split Ratio': split_ratio, 'Max Seq Length': max_seq_length, 'Accuracy': accuracy})\n","    return pd.DataFrame(results), models\n","\n","# Example usage\n","split_ratios = [0.2, 0.4]  # Example split ratios\n","model_names = ['Simple RNN', 'LSTM']  # Example model names\n","max_seq_lengths = [50, 100]  # Example max sequence lengths\n","results_df, models = evaluate_models_with_varied_splits(df, split_ratios, model_names, max_seq_lengths)\n","print(results_df)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T17:25:31.760140Z","iopub.status.busy":"2024-05-15T17:25:31.759695Z","iopub.status.idle":"2024-05-15T17:26:29.942741Z","shell.execute_reply":"2024-05-15T17:26:29.940796Z","shell.execute_reply.started":"2024-05-15T17:25:31.760109Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter cleaned review (or 'exit' to quit):  I really liked the product it was great\n","Enter sentiment:  positive\n","Enter cleaned review (or 'exit' to quit):  I hated the product it was horrible\n","Enter sentiment:  negative\n","Enter cleaned review (or 'exit' to quit):  it was vey mediocre but it works\n","Enter sentiment:  neutral\n","Enter cleaned review (or 'exit' to quit):  exit\n"]},{"name":"stdout","output_type":"stream","text":["                            cleaned_review sentiments\n","0  I really liked the product it was great   positive\n","1      I hated the product it was horrible   negative\n","2         it was vey mediocre but it works    neutral\n"]}],"source":["# BONUS TASK!!!!!\n","\n","# Define an empty list to store data\n","data = []\n","\n","# Prompt the user to enter data for each row\n","while True:\n","    cleaned_review = input(\"Enter cleaned review (or 'exit' to quit): \")\n","    if cleaned_review.lower() == 'exit':\n","        break\n","    sentiment = input(\"Enter sentiment: \")\n","\n","    # Append the entered data as a tuple to the list\n","    data.append((cleaned_review, sentiment))\n","\n","# Create a DataFrame from the collected data\n","df2 = pd.DataFrame(data, columns=['cleaned_review', 'sentiments'])\n","\n","# Display the DataFrame\n","print(df2)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T17:26:33.181607Z","iopub.status.busy":"2024-05-15T17:26:33.180055Z","iopub.status.idle":"2024-05-15T17:26:33.204496Z","shell.execute_reply":"2024-05-15T17:26:33.203242Z","shell.execute_reply.started":"2024-05-15T17:26:33.181555Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cleaned_review</th>\n","      <th>sentiments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[128, 221, 16, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[445, 16, 1121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[6961, 3132, 277, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      cleaned_review  sentiments\n","0  [128, 221, 16, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           0\n","1  [445, 16, 1121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           2\n","2  [6961, 3132, 277, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...           1"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df2 = preprocess_and_encode(df2, \"cleaned_review\", 'sentiments')\n","df2"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T17:26:37.656692Z","iopub.status.busy":"2024-05-15T17:26:37.656306Z","iopub.status.idle":"2024-05-15T17:26:37.664719Z","shell.execute_reply":"2024-05-15T17:26:37.663666Z","shell.execute_reply.started":"2024-05-15T17:26:37.656666Z"},"trusted":true},"outputs":[],"source":["X = tf.convert_to_tensor([tf.convert_to_tensor(x) for x in df2[\"cleaned_review\"]])\n","y = tf.convert_to_tensor([tf.convert_to_tensor(x) for x in df2[\"sentiments\"]])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-15T17:31:38.148509Z","iopub.status.busy":"2024-05-15T17:31:38.148026Z","iopub.status.idle":"2024-05-15T17:31:38.252012Z","shell.execute_reply":"2024-05-15T17:31:38.250757Z","shell.execute_reply.started":"2024-05-15T17:31:38.148475Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"]},{"data":{"text/plain":["array([[9.9623436e-01, 3.5648716e-03, 2.0088226e-04],\n","       [7.0451421e-04, 3.1683955e-02, 9.6761161e-01],\n","       [3.6003876e-03, 9.9358046e-01, 2.8191688e-03]], dtype=float32)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["results= models[3].predict(X)\n","results\n","#highest index is the prediction, first index is positive\n","#second is neutral and third is negative\n","#so it predicted [positive, negative, neutral] 100% correct!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3356090,"sourceId":5838031,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
